Application Project Milestone 1

Data Exploration (10pts)
首先，我们要查看目标列（target），即我们希望预测的值。
1. 计算目标列的统计量（如均值、标准差、范围等）。
2. 使用核密度估计（Kernel Density Estimation, KDE） 绘制目标值的分布，并解释该分布的特征。
然后，我们需要分析特征（features） 及其与目标的关系。
1. 计算每个特征的统计量，并使用核密度估计绘制它们的分布。
2. 计算每个特征与目标值的相关性（correlation），并找出相关性最高的 3 个特征。
3. 绘制散点图，展示这 3 个特征与目标值之间的关系，并解释这些关系。
最后，我们需要查看特征之间的关系：
1. 计算所有特征的相关性矩阵，并解释哪些特征彼此高度相关（不必识别所有特征，只需找到一些明显的相关性）。
2. 选择 1 个特征，找出与其相关性最高的 3 个特征，然后绘制一个 4×4 矩阵散点图：其中，每个非对角线部分展示两个特征之间的散点关系。对角线部分展示对应特征的核密度估计。解释这个矩阵散点图的含义。

Data Preprocessing (5pts)
数据通常包含噪声、错误、缺失值等，这些都会影响模型的学习。数据预处理的另一个原因是将特征缩放到相似的范围，以便模型更好地训练。
1. 检查数据中的错误或缺失值。如果有错误或缺失值，使用你选择的方法进行修正。如果没有，跳过这一步。
2. Consider models that learn with gradient descent-based methods. Why would we want to rescale our data in this case?
3. Consider models that perform regularization according to the norm of the parameters. Why would we want to rescale our data in this case?
4. Consider models that learn according to distance measures (SVM, k-nearest neighbors, etc.). Why would we want to rescale our data in this case?
5. 数据标准化或归一化：选择标准化（Standardization）或归一化（Normalization）对数据进行处理。除了这两种方法，还有哪些其他预处理方法？如果你有更好的方法，可以使用，但请解释你的决定。处理后，将数据保持在该格式，以便后续步骤使用。

Prompt: All the data is in train.csv. The first 40 columns correspond to the 40 features, and the last column (target) corresponds to the prediction target. First, you need to find any errors or missing values that may be in our data. If there are any, correct them by your method of choice. Second, we need to Standardize or Normalize the data. What are some other preprocessing methods other than standardization or normalization you can use? If you have any ideas, use them instead of standardization! Make sure you explain your decision.

Baseline Models (8pts)
本部分你需要选择 3 种不同的模型进行训练，不进行过多的超参数调优。目标不是找到最佳模型，而是比较模型的差异，从数据中获得洞见。

正则化线性回归（或核回归）(Regularized Linear Regression (or Kernelized Regression))（选）
k 近邻（k-Nearest Neighbors, KNN）
决策树（Decision Tree）
随机森林回归（Random Forest Regressor）
自适应或梯度提升回归（Adaptive or Gradient Boosting Regressor）
支持向量机（Support Vector Machine, SVM）（选）
高斯过程（Gaussian Process）
神经网络（Neural Network）（选）

对每个模型，执行以下步骤：
1. 使用 k 折交叉验证（k-fold cross-validation）计算训练误差（in-sample error）和测试误差（out-of-sample error）。选择一个合适的损失函数（loss function），并解释为什么选择该损失函数。
（1）对 3 个模型的训练误差（in-sample error）进行成对 t 检验（paired t-test），计算 p 值并解释结果。
（2）对 3 个模型的测试误差（out-of-sample error）进行成对 t 检验（paired t-test），计算 p 值并解释结果。
（3）绘制核密度估计（KDE），查看每个模型每个数据点的训练误差，并解释误差分布。
（4）绘制核密度估计（KDE），查看每个模型每个数据点的测试误差，并解释误差分布。
2. 使用所有分析方法对模型性能进行比较：使用所有四种分析方法比较模型的性能。包括对结果对模型和数据意味着什幺的解释。

Prompt: After Data Preprocessing, we have X_train, X_test, y_train, y_test. Then, we will choose 3 models, including Regularized Linear Regression, Support Vector Machine, Neural Network, to fit on the data. You need to use k-fold cross-validation to compute the in-sample and out-of-sample errors. Choose a suitable loss function for computing the errors and justify your loss function (same across models). Perform a paired t-test comparing the in-sample errors of your 3 models. What are the p-values? Interpret the results. Perform a paired t-test comparing the out-of-sample errors of your 3 models. What are the p-values? Interpret the results. Make a kernel density estimate of the in-sample error of each data point, for each model. Interpret this distribution. Make a kernel density estimate of the out-of-sample error of each data point, for each model. Interpret this distribution. Use all the four analysis approaches to compare the performance your models. Include an interpretation on what the results mean for your models and the data.

Clustering (7pts)
新的特征往往可以通过深入理解数据来生成，K-Means 聚类（k-means clustering）是一种常用的方法。
1. 执行 K-Means 聚类：选择 k=2，在所有特征上运行 K-Means 聚类。绘制散点图：每个点的坐标表示它到两个簇中心的距离。通过颜色、大小或形状表示目标值。以到簇中心的距离作为特征，用线性回归模型预测目标值。评估：这个聚类是否提供了有意义的信息？为什么？
2. 尝试不同的 k 值：重新聚类并用新的特征进行回归预测。较大的 k 值可以提供更多特征，但可能会导致过拟合。选择最有信息量的 k 值，并解释你的选择。

Milestone Report (5pts)
本 Milestone 评分基于 报告质量（而不是 GitHub 代码）。报告应当是排版整齐、详细且自解释的，读者无需阅读代码即可理解你的方法和结果。不能提交手写文档，推荐 LaTeX 排版 PDF，或使用 Word。

报告结构：
简介/摘要：简要描述你的工作内容。(Intro/Summary)
数据分析与预处理：描述数据集的特征和处理方法。(Data Processing)
方法：说明你使用的模型和技术。(Methods)
结果：展示实验结果并解释分析。(Results)
结论：总结你的研究，说明局限性和未来改进方向。(Conclusion) (summary of what you did, the main results, limitations, and how to improve (aka thoughts on future work))

Typically a report consists of a (short) intro/summary of your work, followed by a data and data processing section, then describe the method(s) you implemented and then the results you have achieved. Then finish up with a conclusion (summary of what you did, the main results, limitations, and how to improve (aka thoughts on future work)).
